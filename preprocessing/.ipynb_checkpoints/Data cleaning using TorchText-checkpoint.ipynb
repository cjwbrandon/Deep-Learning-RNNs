{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchText\n",
    "\n",
    "Often, in data science projects or applications, a large amount of time is spent on data preprocessing. This is similar for Natural Language Processing. NLP consists of its own set of data cleaning and processing techniques that is rather different from other applications given its unique data type. \n",
    "\n",
    "Torchtext is a package that helps with this. It consist of data processing utilities which makes cleaning much simpler. They grouped various steps into classes and functions where all we have to do is finding the right ones for our use case. However, it is still important for us to understand the reasons behind each preprocessing step and its possible impacts. Futhermore, this understanding is necessary when we select our hyperparameter. In addition, torchtext also consists of popular dataset for NLP which provides an easy source to test our algorithms without needing to search for dataset or importing from a secondary source.\n",
    "\n",
    "In this script, I will go through a bunch of functions that is expected to be commonly used, their hyperparameters and their outputs.\n",
    "\n",
    "References:\n",
    "torchtext - https://pytorch.org/text/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data\n",
    "In most cases, we will end up with data stored in a csv or txt file format. We will begin exploring from the importing of the file itself. I will be using the Toxic Comment Classification dataset to explore the different functions available. This dataset is saved as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.read_csv('../../data/NLP/jigsaw-toxic-comment-classification-challenge/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: id, comment_text, toxic, severe_toxic, obscene, threat, insult, identity_hate\n",
      "Number of Rows: 159571\n"
     ]
    }
   ],
   "source": [
    "print(f\"Columns: {', '.join(text.columns)}\")\n",
    "print(f\"Number of Rows: {text.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fields - Center piece of torchtext\n",
    "\n",
    "Before we continue with the importing of our data, we first have to understand a Fields type classes. Fields can be seen as the preprocessing machine/ pipeline. It consists of most the commonly used preprocessing transformations/ steps that are controlled using the input variables. For example, eos_token is used to represent the end of a sentence, fix_length represents the need for padding, lower transforms the text to lower cases, and so forth. With this, rather than typing long functions to transform the data, we can simply change a particular input variable from False to True, and torchtext does it for us. They even convert our data into Tensors for us which allow us to directly feed into our Networks, assuming you build them in PyTorch. We often will declare this first, as such, it is ideal if we have an idea of how we want to preprocess the text data. Or, we can just change it along the way.\n",
    "\n",
    "They have a bunch of field classes.\n",
    "1. RawField - A general datatype (most customisable). This is the most primitive class out of the Fields where it does not assume any property of the data type. As such, it does not have any specific variable inputs but instead takes in a preprocessing and postprocessing pipeline that allows you to specify without any limitations. The reason for this is likely because if we want to read a non-text labels file, we can do so using RawField\n",
    "2. Field - Used for common text processing datatypes. This is the simplest data preprocessing class that provides most of the common text processing steps.\n",
    "3. ReversibleField - Field + ability to reverse map our word index to words.\n",
    "4. NestedField - Takes an untokenised string or a list of string tokens and groups and treats them as one field. Basically, it is used for character embeddings where we want to break down into individual alphabets but still contain information of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser = lambda x : x.split() # typical split by spaces\n",
    "prep_text = Field(sequential=True, tokenize = tokeniser, lower=True, batch_first=True, \n",
    "                  eos_token=\"<eos>\", unk_token=\"<unk>\")\n",
    "prep_labels = Field(sequential=False, use_vocab=False, is_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['today,', 'the', 'sky', 'is', 'so', 'blue.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After preprocessing\n",
    "prep_text.preprocess('Today, the sky is so blue.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_labels.preprocess(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "In order to see our Fields perform, we need a dataset to be loaded in-memory. Dataset classes does that for us. The Datasets classes in torchtext loads our files based on a specified path (input). \n",
    "\n",
    "1. TabularDataset - Used to import datasets stored in tabular formats such as csv, tsv or json.\n",
    "2. LanguageModelingDataset - Used for datasets stored in .txt format. Mainly used for Language Models\n",
    "3. TranslationDataset - Used for datasets stored in extensions unique to its language. e.g. English (.en), French (.fr), etc\n",
    "4. SequenceTaggingDataset - Datasets that are seperated by tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features in the dataset --> declare each column in a tuple such that ({name}, {preprocessing object})\n",
    "toxic_fields = [\n",
    "    (\"id\", None), # we do  not need the id\n",
    "    (\"comment_text\", prep_text), # we preprocess using the Field class defined earlier\n",
    "    (\"toxic\", prep_labels), # remaining columns are part of our labels\n",
    "    (\"severe_toxic\", prep_labels),\n",
    "    (\"obscene\", prep_labels),\n",
    "    (\"threat\", prep_labels),\n",
    "    (\"insult\", prep_labels),\n",
    "    (\"identity_hate\", prep_labels)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create class and import dataset\n",
    "toxic_dataset = TabularDataset(path=\"../../data/NLP/jigsaw-toxic-comment-classification-challenge/train.csv\",\n",
    "                               format=\"CSV\",\n",
    "                               fields=toxic_fields,\n",
    "                               skip_header=True\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset classes in torchtext stores the data under 2 variables shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['examples', 'fields'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 variables\n",
    "toxic_dataset.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': None,\n",
       " 'comment_text': <torchtext.data.field.Field at 0x7f4121728210>,\n",
       " 'toxic': <torchtext.data.field.Field at 0x7f4121728250>,\n",
       " 'severe_toxic': <torchtext.data.field.Field at 0x7f4121728250>,\n",
       " 'obscene': <torchtext.data.field.Field at 0x7f4121728250>,\n",
       " 'threat': <torchtext.data.field.Field at 0x7f4121728250>,\n",
       " 'insult': <torchtext.data.field.Field at 0x7f4121728250>,\n",
       " 'identity_hate': <torchtext.data.field.Field at 0x7f4121728250>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fields variable stores our column names in a dictionary as defined earlier\n",
    "toxic_dataset.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torchtext.data.example.Example at 0x7f4121728dd0>,\n",
       " <torchtext.data.example.Example at 0x7f4121728e50>,\n",
       " <torchtext.data.example.Example at 0x7f4121728e90>,\n",
       " <torchtext.data.example.Example at 0x7f4121728ed0>,\n",
       " <torchtext.data.example.Example at 0x7f4121728f50>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examples stores each row in a list\n",
    "toxic_dataset.examples[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comment_text': ['explanation',\n",
       "  'why',\n",
       "  'the',\n",
       "  'edits',\n",
       "  'made',\n",
       "  'under',\n",
       "  'my',\n",
       "  'username',\n",
       "  'hardcore',\n",
       "  'metallica',\n",
       "  'fan',\n",
       "  'were',\n",
       "  'reverted?',\n",
       "  'they',\n",
       "  \"weren't\",\n",
       "  'vandalisms,',\n",
       "  'just',\n",
       "  'closure',\n",
       "  'on',\n",
       "  'some',\n",
       "  'gas',\n",
       "  'after',\n",
       "  'i',\n",
       "  'voted',\n",
       "  'at',\n",
       "  'new',\n",
       "  'york',\n",
       "  'dolls',\n",
       "  'fac.',\n",
       "  'and',\n",
       "  'please',\n",
       "  \"don't\",\n",
       "  'remove',\n",
       "  'the',\n",
       "  'template',\n",
       "  'from',\n",
       "  'the',\n",
       "  'talk',\n",
       "  'page',\n",
       "  'since',\n",
       "  \"i'm\",\n",
       "  'retired',\n",
       "  'now.89.205.38.27'],\n",
       " 'toxic': '0',\n",
       " 'severe_toxic': '0',\n",
       " 'obscene': '0',\n",
       " 'threat': '0',\n",
       " 'insult': '0',\n",
       " 'identity_hate': '0'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example object used to store our data\n",
    "toxic_dataset.examples[0].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting our data\n",
    "\n",
    "Often, we will split our dataset into a train, validation & test set depending on each individual approach. We can do so using torchtext via the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "train, val = toxic_dataset.split(split_ratio=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Dataset size: 159571\n",
      "Total Train size: 111700\n",
      "Total Validation size: 47871\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Dataset size: {len(toxic_dataset.examples)}\")\n",
    "print(f\"Total Train size: {len(train.examples)}\")\n",
    "print(f\"Total Validation size: {len(val.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can split 3 ways as well\n",
    "# Note: torchtext output and input split_ratio order is in a different order\n",
    "# split returns in the following order --> train, validation, test splits\n",
    "# split split_ratio input is in the following order --> train, test, validation splits\n",
    "train_size, val_size, test_size = 0.7, 0.1, 0.2\n",
    "train, val, test = toxic_dataset.split(split_ratio=[train_size, test_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Dataset size: 159571\n",
      "Total Train size: 111700\n",
      "Total Validation size: 15957\n",
      "Total Test size: 31914\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Dataset size: {len(toxic_dataset.examples)}\")\n",
    "print(f\"Total Train size: {len(train.examples)}\")\n",
    "print(f\"Total Validation size: {len(val.examples)}\")\n",
    "print(f\"Total Test size: {len(test.examples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, if you have the splits saved in different csv files, torchtext can load the data using the different file paths as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = TabularDataset.splits(path=\"../../data/NLP/jigsaw-toxic-comment-classification-challenge\",\n",
    "                                    train=\"train.csv\", test=\"test.csv\", # splits path, they  have a validation input as well\n",
    "                                    format=\"CSV\", fields=toxic_fields, skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.data.dataset.TabularDataset'>\n",
      "<class 'torchtext.data.dataset.TabularDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train))\n",
    "print(type(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train size: 159571\n",
      "Total Test size: 153164\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Train size: {len(train.examples)}\")\n",
    "print(f\"Total Test size: {len(test.examples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fields Functions\n",
    "Now that we have initialise our Datasets, we can look into some of the Fields' functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build our vocab list\n",
    "# one of the first things you want to do is to build our vacabulary list\n",
    "# we will want to do this one our train set\n",
    "prep_text.build_vocab(train.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.vocab.Vocab at 0x7f409b9cf210>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the Field object stores the vocab list in an torchtext object called Vocab under a variable called vocab\n",
    "prep_text.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7f409b9cf210>>,\n",
       "            {'<unk>': 0,\n",
       "             '<pad>': 1,\n",
       "             '<eos>': 2,\n",
       "             'the': 3,\n",
       "             'to': 4,\n",
       "             'of': 5,\n",
       "             'and': 6,\n",
       "             'a': 7,\n",
       "             'i': 8,\n",
       "             'you': 9,\n",
       "             'is': 10,\n",
       "             'that': 11,\n",
       "             'in': 12,\n",
       "             'it': 13,\n",
       "             'for': 14,\n",
       "             'not': 15,\n",
       "             'this': 16,\n",
       "             'on': 17,\n",
       "             'be': 18,\n",
       "             '\"': 19,\n",
       "             'as': 20,\n",
       "             'have': 21,\n",
       "             'are': 22,\n",
       "             'your': 23,\n",
       "             'with': 24,\n",
       "             'if': 25,\n",
       "             'was': 26,\n",
       "             'or': 27,\n",
       "             'but': 28,\n",
       "             'my': 29,\n",
       "             'an': 30,\n",
       "             'by': 31,\n",
       "             'from': 32,\n",
       "             'article': 33,\n",
       "             'at': 34,\n",
       "             'do': 35,\n",
       "             'about': 36,\n",
       "             'can': 37,\n",
       "             'what': 38,\n",
       "             'so': 39,\n",
       "             'has': 40,\n",
       "             'will': 41,\n",
       "             'would': 42,\n",
       "             'page': 43,\n",
       "             'there': 44,\n",
       "             'please': 45,\n",
       "             'all': 46,\n",
       "             'just': 47,\n",
       "             'they': 48,\n",
       "             'me': 49,\n",
       "             'like': 50,\n",
       "             'no': 51,\n",
       "             'he': 52,\n",
       "             'been': 53,\n",
       "             'any': 54,\n",
       "             'one': 55,\n",
       "             'should': 56,\n",
       "             '-': 57,\n",
       "             'which': 58,\n",
       "             'talk': 59,\n",
       "             'we': 60,\n",
       "             'wikipedia': 61,\n",
       "             \"don't\": 62,\n",
       "             'some': 63,\n",
       "             'more': 64,\n",
       "             'other': 65,\n",
       "             'who': 66,\n",
       "             'his': 67,\n",
       "             'think': 68,\n",
       "             'see': 69,\n",
       "             'because': 70,\n",
       "             'how': 71,\n",
       "             'am': 72,\n",
       "             \"i'm\": 73,\n",
       "             \"it's\": 74,\n",
       "             'only': 75,\n",
       "             'why': 76,\n",
       "             'also': 77,\n",
       "             'know': 78,\n",
       "             'when': 79,\n",
       "             'may': 80,\n",
       "             'edit': 81,\n",
       "             'were': 82,\n",
       "             'people': 83,\n",
       "             'then': 84,\n",
       "             'out': 85,\n",
       "             'use': 86,\n",
       "             'their': 87,\n",
       "             'being': 88,\n",
       "             'than': 89,\n",
       "             'did': 90,\n",
       "             'up': 91,\n",
       "             'get': 92,\n",
       "             'even': 93,\n",
       "             'make': 94,\n",
       "             'had': 95,\n",
       "             'here': 96,\n",
       "             'very': 97,\n",
       "             'could': 98,\n",
       "             'does': 99,\n",
       "             'articles': 100,\n",
       "             'its': 101,\n",
       "             'good': 102,\n",
       "             'want': 103,\n",
       "             'these': 104,\n",
       "             'such': 105,\n",
       "             'time': 106,\n",
       "             'them': 107,\n",
       "             'it.': 108,\n",
       "             'need': 109,\n",
       "             'new': 110,\n",
       "             'thank': 111,\n",
       "             'now': 112,\n",
       "             'go': 113,\n",
       "             'where': 114,\n",
       "             'first': 115,\n",
       "             'information': 116,\n",
       "             'many': 117,\n",
       "             'made': 118,\n",
       "             'into': 119,\n",
       "             'find': 120,\n",
       "             'page.': 121,\n",
       "             'name': 122,\n",
       "             'most': 123,\n",
       "             'really': 124,\n",
       "             \"i've\": 125,\n",
       "             'thanks': 126,\n",
       "             'those': 127,\n",
       "             'say': 128,\n",
       "             'fuck': 129,\n",
       "             'much': 130,\n",
       "             'used': 131,\n",
       "             'since': 132,\n",
       "             'same': 133,\n",
       "             'article.': 134,\n",
       "             'user': 135,\n",
       "             'after': 136,\n",
       "             'add': 137,\n",
       "             'way': 138,\n",
       "             'take': 139,\n",
       "             'help': 140,\n",
       "             'sources': 141,\n",
       "             'look': 142,\n",
       "             'someone': 143,\n",
       "             'still': 144,\n",
       "             'read': 145,\n",
       "             'section': 146,\n",
       "             'over': 147,\n",
       "             'pages': 148,\n",
       "             'before': 149,\n",
       "             'going': 150,\n",
       "             'two': 151,\n",
       "             'deletion': 152,\n",
       "             \"you're\": 153,\n",
       "             'you.': 154,\n",
       "             'source': 155,\n",
       "             'edits': 156,\n",
       "             'without': 157,\n",
       "             'discussion': 158,\n",
       "             'well': 159,\n",
       "             'own': 160,\n",
       "             'our': 161,\n",
       "             'editing': 162,\n",
       "             'under': 163,\n",
       "             'wikipedia.': 164,\n",
       "             'point': 165,\n",
       "             'deleted': 166,\n",
       "             'back': 167,\n",
       "             'might': 168,\n",
       "             'work': 169,\n",
       "             'something': 170,\n",
       "             'image': 171,\n",
       "             'another': 172,\n",
       "             'added': 173,\n",
       "             'never': 174,\n",
       "             \"doesn't\": 175,\n",
       "             'put': 176,\n",
       "             'link': 177,\n",
       "             'seems': 178,\n",
       "             'stop': 179,\n",
       "             ',': 180,\n",
       "             \"that's\": 181,\n",
       "             'blocked': 182,\n",
       "             'feel': 183,\n",
       "             '.': 184,\n",
       "             'list': 185,\n",
       "             'block': 186,\n",
       "             'right': 187,\n",
       "             'said': 188,\n",
       "             '(utc)': 189,\n",
       "             'using': 190,\n",
       "             'ask': 191,\n",
       "             'personal': 192,\n",
       "             'fact': 193,\n",
       "             'sure': 194,\n",
       "             'him': 195,\n",
       "             'her': 196,\n",
       "             'article,': 197,\n",
       "             'believe': 198,\n",
       "             'while': 199,\n",
       "             'hope': 200,\n",
       "             'page,': 201,\n",
       "             'both': 202,\n",
       "             'against': 203,\n",
       "             'note': 204,\n",
       "             'she': 205,\n",
       "             '•': 206,\n",
       "             'actually': 207,\n",
       "             \"can't\": 208,\n",
       "             \"i'll\": 209,\n",
       "             'editors': 210,\n",
       "             \"didn't\": 211,\n",
       "             'keep': 212,\n",
       "             'place': 213,\n",
       "             'too': 214,\n",
       "             'remove': 215,\n",
       "             'better': 216,\n",
       "             'done': 217,\n",
       "             'part': 218,\n",
       "             'free': 219,\n",
       "             'trying': 220,\n",
       "             'reason': 221,\n",
       "             'comment': 222,\n",
       "             'it,': 223,\n",
       "             'little': 224,\n",
       "             'must': 225,\n",
       "             'links': 226,\n",
       "             'content': 227,\n",
       "             'best': 228,\n",
       "             'history': 229,\n",
       "             'few': 230,\n",
       "             'speedy': 231,\n",
       "             'already': 232,\n",
       "             'anything': 233,\n",
       "             'give': 234,\n",
       "             'nothing': 235,\n",
       "             'copyright': 236,\n",
       "             'us': 237,\n",
       "             'let': 238,\n",
       "             'removed': 239,\n",
       "             'things': 240,\n",
       "             'hi': 241,\n",
       "             'however,': 242,\n",
       "             'comments': 243,\n",
       "             'last': 244,\n",
       "             'wiki': 245,\n",
       "             'making': 246,\n",
       "             'rather': 247,\n",
       "             'change': 248,\n",
       "             'me.': 249,\n",
       "             'come': 250,\n",
       "             'welcome': 251,\n",
       "             'person': 252,\n",
       "             '|': 253,\n",
       "             'anyone': 254,\n",
       "             'question': 255,\n",
       "             'off': 256,\n",
       "             'try': 257,\n",
       "             '(talk)': 258,\n",
       "             'understand': 259,\n",
       "             'different': 260,\n",
       "             'here.': 261,\n",
       "             'got': 262,\n",
       "             'leave': 263,\n",
       "             'continue': 264,\n",
       "             'every': 265,\n",
       "             'simply': 266,\n",
       "             'long': 267,\n",
       "             'found': 268,\n",
       "             'probably': 269,\n",
       "             'reliable': 270,\n",
       "             \"isn't\": 271,\n",
       "             'adding': 272,\n",
       "             'you,': 273,\n",
       "             'original': 274,\n",
       "             'doing': 275,\n",
       "             'agree': 276,\n",
       "             ')': 277,\n",
       "             'check': 278,\n",
       "             'between': 279,\n",
       "             '—': 280,\n",
       "             'case': 281,\n",
       "             'delete': 282,\n",
       "             'tag': 283,\n",
       "             'great': 284,\n",
       "             'again': 285,\n",
       "             'fair': 286,\n",
       "             'subject': 287,\n",
       "             'through': 288,\n",
       "             'having': 289,\n",
       "             'thing': 290,\n",
       "             'mean': 291,\n",
       "             'seem': 292,\n",
       "             'u': 293,\n",
       "             'reference': 294,\n",
       "             'least': 295,\n",
       "             'says': 296,\n",
       "             'needs': 297,\n",
       "             'problem': 298,\n",
       "             'ip': 299,\n",
       "             'write': 300,\n",
       "             'show': 301,\n",
       "             'given': 302,\n",
       "             'editor': 303,\n",
       "             'called': 304,\n",
       "             'clearly': 305,\n",
       "             'word': 306,\n",
       "             'thought': 307,\n",
       "             'quite': 308,\n",
       "             'policy': 309,\n",
       "             'tell': 310,\n",
       "             'lot': 311,\n",
       "             'text': 312,\n",
       "             'until': 313,\n",
       "             'far': 314,\n",
       "             \"i'd\": 315,\n",
       "             'always': 316,\n",
       "             'also,': 317,\n",
       "             'whether': 318,\n",
       "             'hate': 319,\n",
       "             'vandalism': 320,\n",
       "             'consider': 321,\n",
       "             'issue': 322,\n",
       "             'maybe': 323,\n",
       "             'around': 324,\n",
       "             'request': 325,\n",
       "             'real': 326,\n",
       "             'others': 327,\n",
       "             'state': 328,\n",
       "             'getting': 329,\n",
       "             'fucking': 330,\n",
       "             'ever': 331,\n",
       "             'years': 332,\n",
       "             'nigger': 333,\n",
       "             'though': 334,\n",
       "             'post': 335,\n",
       "             'again,': 336,\n",
       "             'references': 337,\n",
       "             'so,': 338,\n",
       "             'created': 339,\n",
       "             'world': 340,\n",
       "             'makes': 341,\n",
       "             'me,': 342,\n",
       "             'number': 343,\n",
       "             'several': 344,\n",
       "             'questions': 345,\n",
       "             'english': 346,\n",
       "             'saying': 347,\n",
       "             'perhaps': 348,\n",
       "             'either': 349,\n",
       "             'this.': 350,\n",
       "             'support': 351,\n",
       "             'bad': 352,\n",
       "             'enough': 353,\n",
       "             'considered': 354,\n",
       "             'cannot': 355,\n",
       "             'wikipedia,': 356,\n",
       "             'that.': 357,\n",
       "             \"there's\": 358,\n",
       "             'mention': 359,\n",
       "             'reverted': 360,\n",
       "             'old': 361,\n",
       "             'once': 362,\n",
       "             'wrong': 363,\n",
       "             'down': 364,\n",
       "             'above': 365,\n",
       "             'sorry': 366,\n",
       "             'bit': 367,\n",
       "             'based': 368,\n",
       "             'important': 369,\n",
       "             'clear': 370,\n",
       "             'images': 371,\n",
       "             'each': 372,\n",
       "             'written': 373,\n",
       "             'suck': 374,\n",
       "             'further': 375,\n",
       "             'regarding': 376,\n",
       "             'criteria': 377,\n",
       "             'current': 378,\n",
       "             '&': 379,\n",
       "             'yet': 380,\n",
       "             'claim': 381,\n",
       "             'consensus': 382,\n",
       "             'shit': 383,\n",
       "             'book': 384,\n",
       "             'evidence': 385,\n",
       "             'yourself': 386,\n",
       "             'main': 387,\n",
       "             'material': 388,\n",
       "             'users': 389,\n",
       "             'else': 390,\n",
       "             'matter': 391,\n",
       "             'instead': 392,\n",
       "             'dont': 393,\n",
       "             'message': 394,\n",
       "             'following': 395,\n",
       "             'revert': 396,\n",
       "             '\"\"the': 397,\n",
       "             'term': 398,\n",
       "             'listed': 399,\n",
       "             'top': 400,\n",
       "             'site': 401,\n",
       "             'include': 402,\n",
       "             'whole': 403,\n",
       "             'kind': 404,\n",
       "             'three': 405,\n",
       "             'view': 406,\n",
       "             'thanks.': 407,\n",
       "             'account': 408,\n",
       "             'that,': 409,\n",
       "             'seen': 410,\n",
       "             '2': 411,\n",
       "             'call': 412,\n",
       "             'media': 413,\n",
       "             '(and': 414,\n",
       "             'create': 415,\n",
       "             'this,': 416,\n",
       "             \"wikipedia's\": 417,\n",
       "             'admin': 418,\n",
       "             'provide': 419,\n",
       "             'suggest': 420,\n",
       "             'them.': 421,\n",
       "             'time.': 422,\n",
       "             'notice': 423,\n",
       "             'left': 424,\n",
       "             'version': 425,\n",
       "             'happy': 426,\n",
       "             'means': 427,\n",
       "             'here,': 428,\n",
       "             'less': 429,\n",
       "             'start': 430,\n",
       "             'day': 431,\n",
       "             'states': 432,\n",
       "             'big': 433,\n",
       "             'opinion': 434,\n",
       "             'idea': 435,\n",
       "             'care': 436,\n",
       "             'removing': 437,\n",
       "             'war': 438,\n",
       "             'mentioned': 439,\n",
       "             'review': 440,\n",
       "             'changes': 441,\n",
       "             'second': 442,\n",
       "             'looking': 443,\n",
       "             'life': 444,\n",
       "             '==': 445,\n",
       "             'explain': 446,\n",
       "             'correct': 447,\n",
       "             \"you've\": 448,\n",
       "             'title': 449,\n",
       "             'sign': 450,\n",
       "             'is,': 451,\n",
       "             'language': 452,\n",
       "             'general': 453,\n",
       "             'known': 454,\n",
       "             'recent': 455,\n",
       "             'four': 456,\n",
       "             'including': 457,\n",
       "             'able': 458,\n",
       "             'love': 459,\n",
       "             'well,': 460,\n",
       "             'started': 461,\n",
       "             'redirect': 462,\n",
       "             'per': 463,\n",
       "             'next': 464,\n",
       "             'american': 465,\n",
       "             'group': 466,\n",
       "             '3': 467,\n",
       "             'move': 468,\n",
       "             'within': 469,\n",
       "             'times': 470,\n",
       "             'during': 471,\n",
       "             'statement': 472,\n",
       "             'full': 473,\n",
       "             'changed': 474,\n",
       "             'currently': 475,\n",
       "             'appears': 476,\n",
       "             'oh': 477,\n",
       "             'editing.': 478,\n",
       "             'specific': 479,\n",
       "             'end': 480,\n",
       "             'wanted': 481,\n",
       "             'discuss': 482,\n",
       "             'research': 483,\n",
       "             'address': 484,\n",
       "             'certainly': 485,\n",
       "             'pov': 486,\n",
       "             'pretty': 487,\n",
       "             'gay': 488,\n",
       "             '2005': 489,\n",
       "             'yes,': 490,\n",
       "             'interested': 491,\n",
       "             'related': 492,\n",
       "             'especially': 493,\n",
       "             'template': 494,\n",
       "             'looks': 495,\n",
       "             'although': 496,\n",
       "             'now,': 497,\n",
       "             'possible': 498,\n",
       "             'die': 499,\n",
       "             'order': 500,\n",
       "             'website': 501,\n",
       "             'articles.': 502,\n",
       "             'included': 503,\n",
       "             'words': 504,\n",
       "             'came': 505,\n",
       "             'completely': 506,\n",
       "             \"won't\": 507,\n",
       "             'unless': 508,\n",
       "             'fat': 509,\n",
       "             'taken': 510,\n",
       "             'rules': 511,\n",
       "             'answer': 512,\n",
       "             'relevant': 513,\n",
       "             'writing': 514,\n",
       "             'according': 515,\n",
       "             'issues': 516,\n",
       "             'there.': 517,\n",
       "             'guidelines': 518,\n",
       "             'wish': 519,\n",
       "             'public': 520,\n",
       "             'info': 521,\n",
       "             'due': 522,\n",
       "             'live': 523,\n",
       "             'single': 524,\n",
       "             '(talk': 525,\n",
       "             'official': 526,\n",
       "             'wrote': 527,\n",
       "             'true': 528,\n",
       "             'hey': 529,\n",
       "             'common': 530,\n",
       "             \"he's\": 531,\n",
       "             \"wasn't\": 532,\n",
       "             'learn': 533,\n",
       "             'year': 534,\n",
       "             'style': 535,\n",
       "             'placed': 536,\n",
       "             'contributions': 537,\n",
       "             'talking': 538,\n",
       "             'sentence': 539,\n",
       "             'again.': 540,\n",
       "             'nor': 541,\n",
       "             'notability': 542,\n",
       "             'notable': 543,\n",
       "             'picture': 544,\n",
       "             'hard': 545,\n",
       "             '1': 546,\n",
       "             '–': 547,\n",
       "             'asked': 548,\n",
       "             'web': 549,\n",
       "             'facts': 550,\n",
       "             'example': 551,\n",
       "             'everyone': 552,\n",
       "             'claims': 553,\n",
       "             'away': 554,\n",
       "             'appreciate': 555,\n",
       "             'now.': 556,\n",
       "             'edited': 557,\n",
       "             'nice': 558,\n",
       "             'appropriate': 559,\n",
       "             '...': 560,\n",
       "             'interest': 561,\n",
       "             'posted': 562,\n",
       "             'everything': 563,\n",
       "             'reading': 564,\n",
       "             'report': 565,\n",
       "             'obviously': 566,\n",
       "             'you!': 567,\n",
       "             'working': 568,\n",
       "             'political': 569,\n",
       "             'do.': 570,\n",
       "             'school': 571,\n",
       "             'deletion,': 572,\n",
       "             'deleting': 573,\n",
       "             '=': 574,\n",
       "             'attack': 575,\n",
       "             'noticed': 576,\n",
       "             'etc.': 577,\n",
       "             'united': 578,\n",
       "             'five': 579,\n",
       "             'become': 580,\n",
       "             'high': 581,\n",
       "             'lol': 582,\n",
       "             'remember': 583,\n",
       "             'took': 584,\n",
       "             'pages,': 585,\n",
       "             'major': 586,\n",
       "             'hello,': 587,\n",
       "             'exactly': 588,\n",
       "             'taking': 589,\n",
       "             'tried': 590,\n",
       "             'faggot': 591,\n",
       "             'almost': 592,\n",
       "             'sense': 593,\n",
       "             'summary': 594,\n",
       "             'topic': 595,\n",
       "             'moron': 596,\n",
       "             'entire': 597,\n",
       "             'neutral': 598,\n",
       "             'mind': 599,\n",
       "             '(or': 600,\n",
       "             'community': 601,\n",
       "             'vandalize': 602,\n",
       "             'similar': 603,\n",
       "             'line': 604,\n",
       "             \"haven't\": 605,\n",
       "             'published': 606,\n",
       "             'articles,': 607,\n",
       "             'ass': 608,\n",
       "             'national': 609,\n",
       "             'wikipedia!': 610,\n",
       "             'certain': 611,\n",
       "             'reverting': 612,\n",
       "             'man': 613,\n",
       "             'stupid': 614,\n",
       "             'news': 615,\n",
       "             '(': 616,\n",
       "             'lead': 617,\n",
       "             'way,': 618,\n",
       "             'warning': 619,\n",
       "             'policies': 620,\n",
       "             'names': 621,\n",
       "             'stuff': 622,\n",
       "             'sources.': 623,\n",
       "             'project': 624,\n",
       "             'saw': 625,\n",
       "             'however': 626,\n",
       "             '?': 627,\n",
       "             'particular': 628,\n",
       "             'guess': 629,\n",
       "             'time,': 630,\n",
       "             'quote': 631,\n",
       "             'often': 632,\n",
       "             'sort': 633,\n",
       "             'aware': 634,\n",
       "             'later': 635,\n",
       "             'actual': 636,\n",
       "             'search': 637,\n",
       "             'likely': 638,\n",
       "             'follow': 639,\n",
       "             'involved': 640,\n",
       "             'appear': 641,\n",
       "             'days': 642,\n",
       "             \"article's\": 643,\n",
       "             'various': 644,\n",
       "             'along': 645,\n",
       "             'course': 646,\n",
       "             'not.': 647,\n",
       "             'hello': 648,\n",
       "             'stated': 649,\n",
       "             'decide': 650,\n",
       "             'british': 651,\n",
       "             'power': 652,\n",
       "             'whatever': 653,\n",
       "             'encyclopedia.': 654,\n",
       "             'generally': 655,\n",
       "             'shows': 656,\n",
       "             'external': 657,\n",
       "             'myself': 658,\n",
       "             'contributing': 659,\n",
       "             'told': 660,\n",
       "             'therefore': 661,\n",
       "             'improve': 662,\n",
       "             'is.': 663,\n",
       "             'description': 664,\n",
       "             'went': 665,\n",
       "             'set': 666,\n",
       "             'past': 667,\n",
       "             'provided': 668,\n",
       "             'previous': 669,\n",
       "             'response': 670,\n",
       "             'guy': 671,\n",
       "             'proposed': 672,\n",
       "             'piece': 673,\n",
       "             'form': 674,\n",
       "             'all.': 675,\n",
       "             'vandalism.': 676,\n",
       "             'deleted.': 677,\n",
       "             'below': 678,\n",
       "             'contact': 679,\n",
       "             'too.': 680,\n",
       "             'useful': 681,\n",
       "             'deletion.': 682,\n",
       "             'moved': 683,\n",
       "             'it?': 684,\n",
       "             'well.': 685,\n",
       "             \"wouldn't\": 686,\n",
       "             '2006': 687,\n",
       "             \"aren't\": 688,\n",
       "             '4': 689,\n",
       "             'encyclopedia': 690,\n",
       "             'government': 691,\n",
       "             'open': 692,\n",
       "             'false': 693,\n",
       "             'removed.': 694,\n",
       "             'enjoy': 695,\n",
       "             'small': 696,\n",
       "             'god': 697,\n",
       "             'creating': 698,\n",
       "             'google': 699,\n",
       "             'present': 700,\n",
       "             'automatically': 701,\n",
       "             'hi,': 702,\n",
       "             '/': 703,\n",
       "             'admins': 704,\n",
       "             'paragraph': 705,\n",
       "             'jew': 706,\n",
       "             '(i': 707,\n",
       "             'recently': 708,\n",
       "             '(which': 709,\n",
       "             'attacks': 710,\n",
       "             \"what's\": 711,\n",
       "             'argument': 712,\n",
       "             'comes': 713,\n",
       "             'type': 714,\n",
       "             'uploaded': 715,\n",
       "             'information.': 716,\n",
       "             'terms': 717,\n",
       "             'avoid': 718,\n",
       "             \"shouldn't\": 719,\n",
       "             'city': 720,\n",
       "             'im': 721,\n",
       "             'indicate': 722,\n",
       "             'sucks': 723,\n",
       "             'proper': 724,\n",
       "             'case,': 725,\n",
       "             '(the': 726,\n",
       "             'dispute': 727,\n",
       "             'faith': 728,\n",
       "             'side': 729,\n",
       "             'cited': 730,\n",
       "             'allowed': 731,\n",
       "             'country': 732,\n",
       "             'you?': 733,\n",
       "             'ban': 734,\n",
       "             'test': 735,\n",
       "             'guys': 736,\n",
       "             '2004': 737,\n",
       "             'cite': 738,\n",
       "             'no,': 739,\n",
       "             'attempt': 740,\n",
       "             'one.': 741,\n",
       "             'obvious': 742,\n",
       "             'short': 743,\n",
       "             'problems': 744,\n",
       "             'accept': 745,\n",
       "             'party': 746,\n",
       "             'longer': 747,\n",
       "             '5': 748,\n",
       "             'calling': 749,\n",
       "             'definition': 750,\n",
       "             'itself': 751,\n",
       "             'pig': 752,\n",
       "             'human': 753,\n",
       "             'large': 754,\n",
       "             'points': 755,\n",
       "             'them,': 756,\n",
       "             'tildes': 757,\n",
       "             'welcome!': 758,\n",
       "             \"they're\": 759,\n",
       "             'explanation': 760,\n",
       "             'wp': 761,\n",
       "             'knowledge': 762,\n",
       "             \"you'll\": 763,\n",
       "             'username': 764,\n",
       "             'game': 765,\n",
       "             'source.': 766,\n",
       "             'goes': 767,\n",
       "             'multiple': 768,\n",
       "             'assume': 769,\n",
       "             'explaining': 770,\n",
       "             'john': 771,\n",
       "             'living': 772,\n",
       "             'banned': 773,\n",
       "             'file': 774,\n",
       "             \"let's\": 775,\n",
       "             'simple': 776,\n",
       "             'refer': 777,\n",
       "             'result': 778,\n",
       "             'thanks,': 779,\n",
       "             'example,': 780,\n",
       "             'manual': 781,\n",
       "             'administrator': 782,\n",
       "             'separate': 783,\n",
       "             'usually': 784,\n",
       "             'lack': 785,\n",
       "             'historical': 786,\n",
       "             'up.': 787,\n",
       "             'all,': 788,\n",
       "             '2007': 789,\n",
       "             'copy': 790,\n",
       "             'upon': 791,\n",
       "             'system': 792,\n",
       "             'contribs)': 793,\n",
       "             'reasons': 794,\n",
       "             'date': 795,\n",
       "             'accepted': 796,\n",
       "             'music': 797,\n",
       "             '2008': 798,\n",
       "             'july': 799,\n",
       "             'books': 800,\n",
       "             'entry': 801,\n",
       "             'tags': 802,\n",
       "             'family': 803,\n",
       "             'members': 804,\n",
       "             'reply': 805,\n",
       "             'interesting': 806,\n",
       "             'conflict': 807,\n",
       "             'deal': 808,\n",
       "             'fix': 809,\n",
       "             'rule': 810,\n",
       "             'supposed': 811,\n",
       "             'rest': 812,\n",
       "             'law': 813,\n",
       "             'black': 814,\n",
       "             'heard': 815,\n",
       "             'couple': 816,\n",
       "             'gets': 817,\n",
       "             'asking': 818,\n",
       "             'respect': 819,\n",
       "             'tagged': 820,\n",
       "             'thus': 821,\n",
       "             'white': 822,\n",
       "             'prove': 823,\n",
       "             'university': 824,\n",
       "             '(see': 825,\n",
       "             'disagree': 826,\n",
       "             'valid': 827,\n",
       "             'act': 828,\n",
       "             'date.': 829,\n",
       "             'huge': 830,\n",
       "             'sex': 831,\n",
       "             'german': 832,\n",
       "             'there,': 833,\n",
       "             'among': 834,\n",
       "             'play': 835,\n",
       "             'blocking': 836,\n",
       "             'existing': 837,\n",
       "             'fact,': 838,\n",
       "             'content,': 839,\n",
       "             'edits,': 840,\n",
       "             'produce': 841,\n",
       "             '!': 842,\n",
       "             'sandbox': 843,\n",
       "             'edits.': 844,\n",
       "             'jews': 845,\n",
       "             'pillars': 846,\n",
       "             'views': 847,\n",
       "             'internet': 848,\n",
       "             'future': 849,\n",
       "             'attention': 850,\n",
       "             'help,': 851,\n",
       "             'august': 852,\n",
       "             'status': 853,\n",
       "             'legal': 854,\n",
       "             'section.': 855,\n",
       "             'unblock': 856,\n",
       "             'out.': 857,\n",
       "             'changing': 858,\n",
       "             'doubt': 859,\n",
       "             'film': 860,\n",
       "             'citation': 861,\n",
       "             'cause': 862,\n",
       "             'described': 863,\n",
       "             'needed': 864,\n",
       "             'complete': 865,\n",
       "             'process': 866,\n",
       "             'so.': 867,\n",
       "             'not,': 868,\n",
       "             'yourself,': 869,\n",
       "             'early': 870,\n",
       "             'fish': 871,\n",
       "             'video': 872,\n",
       "             'email': 873,\n",
       "             'gave': 874,\n",
       "             'indeed': 875,\n",
       "             'serious': 876,\n",
       "             'sources,': 877,\n",
       "             'statements': 878,\n",
       "             'author': 879,\n",
       "             'shall': 880,\n",
       "             'anyway,': 881,\n",
       "             'truth': 882,\n",
       "             'meant': 883,\n",
       "             'south': 884,\n",
       "             '(as': 885,\n",
       "             'third': 886,\n",
       "             'meaning': 887,\n",
       "             'people,': 888,\n",
       "             'primary': 889,\n",
       "             'march': 890,\n",
       "             'week': 891,\n",
       "             'allow': 892,\n",
       "             'ones': 893,\n",
       "             'available': 894,\n",
       "             'bring': 895,\n",
       "             'dick': 896,\n",
       "             'giving': 897,\n",
       "             'proof': 898,\n",
       "             'stay': 899,\n",
       "             'uses': 900,\n",
       "             'yes': 901,\n",
       "             'takes': 902,\n",
       "             'way.': 903,\n",
       "             'close': 904,\n",
       "             'none': 905,\n",
       "             'putting': 906,\n",
       "             'themselves': 907,\n",
       "             'merely': 908,\n",
       "             'position': 909,\n",
       "             'wikiproject': 910,\n",
       "             '10': 911,\n",
       "             'actions': 912,\n",
       "             'outside': 913,\n",
       "             'story': 914,\n",
       "             'standard': 915,\n",
       "             'addition': 916,\n",
       "             'modern': 917,\n",
       "             'tutorial': 918,\n",
       "             'directly': 919,\n",
       "             'run': 920,\n",
       "             'soon': 921,\n",
       "             'speak': 922,\n",
       "             'totally': 923,\n",
       "             'apparently': 924,\n",
       "             'hours': 925,\n",
       "             'towards': 926,\n",
       "             'category': 927,\n",
       "             'decided': 928,\n",
       "             'bullshit': 929,\n",
       "             'contest': 930,\n",
       "             'kill': 931,\n",
       "             'particularly': 932,\n",
       "             'greek': 933,\n",
       "             'military': 934,\n",
       "             'coming': 935,\n",
       "             'happened': 936,\n",
       "             'him.': 937,\n",
       "             'criticism': 938,\n",
       "             'except': 939,\n",
       "             'work.': 940,\n",
       "             'know,': 941,\n",
       "             'wrong.': 942,\n",
       "             'june': 943,\n",
       "             'sections': 944,\n",
       "             'absolutely': 945,\n",
       "             'contribute': 946,\n",
       "             'cunt': 947,\n",
       "             'and,': 948,\n",
       "             'de': 949,\n",
       "             'information,': 950,\n",
       "             'rights': 951,\n",
       "             'himself': 952,\n",
       "             'sourced': 953,\n",
       "             'pages.': 954,\n",
       "             'january': 955,\n",
       "             'violation': 956,\n",
       "             'looked': 957,\n",
       "             'ok': 958,\n",
       "             'theory': 959,\n",
       "             'biased': 960,\n",
       "             'unsigned': 961,\n",
       "             'job': 962,\n",
       "             'otherwise': 963,\n",
       "             'area': 964,\n",
       "             'requesting': 965,\n",
       "             \"we're\": 966,\n",
       "             'wants': 967,\n",
       "             'neither': 968,\n",
       "             'scientific': 969,\n",
       "             \"you'd\": 970,\n",
       "             'anonymous': 971,\n",
       "             'death': 972,\n",
       "             'level': 973,\n",
       "             'citations': 974,\n",
       "             'works': 975,\n",
       "             'linked': 976,\n",
       "             'said,': 977,\n",
       "             'significant': 978,\n",
       "             'together': 979,\n",
       "             'opinions': 980,\n",
       "             'reported': 981,\n",
       "             'worth': 982,\n",
       "             '24': 983,\n",
       "             'bark': 984,\n",
       "             'alone': 985,\n",
       "             'gives': 986,\n",
       "             'today': 987,\n",
       "             'sometimes': 988,\n",
       "             'eat': 989,\n",
       "             'thinking': 990,\n",
       "             'meet': 991,\n",
       "             'contributions.': 992,\n",
       "             'majority': 993,\n",
       "             'source,': 994,\n",
       "             'mr.': 995,\n",
       "             'data': 996,\n",
       "             'international': 997,\n",
       "             'posting': 998,\n",
       "             '6': 999,\n",
       "             ...})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_text.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterators\n",
    "\n",
    "Defines an iterator that loads batches of data from a Dataset. Iterators help us mini-batch our dataset using techniques specific to NLP such as batching similar length sentences together to minimise padding.\n",
    "\n",
    "1. Iterator - Simply iterates over the entire dataset in order or based on HPs\n",
    "2. BucketIterator - Iterator + helps you batch examples of similar lengths together to minimise padding.\n",
    "3. BPTTIterator - Defines an iterator for language modeling tasks that use BPTT. Provides examples with targets that are one timestep further forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset iterator\n",
    "train_iter = BucketIterator(dataset=train, \n",
    "                            batch_size=64,\n",
    "                            sort_key=lambda x: len(x.comment_text), # by the length of our comments\n",
    "                            train=True,\n",
    "                            sort=True,\n",
    "                            device='cuda' # set whether to store the tensors on gpu or cpu\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset iterator\n",
    "test_iter = BucketIterator(dataset=test, \n",
    "                           batch_size=64,\n",
    "                           sort_key=lambda x: len(x.comment_text), # by the length of our comments\n",
    "                           train=False,\n",
    "                           sort=True,\n",
    "                           device='cuda' # set whether to store the tensors on gpu or cpu\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a batch\n",
    "sample_batch = next(enumerate(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.cuda.LongTensor of size 64x3 (GPU 0)]\n",
       " \t[.toxic]:[torch.cuda.LongTensor of size 64 (GPU 0)]\n",
       " \t[.severe_toxic]:[torch.cuda.LongTensor of size 64 (GPU 0)]\n",
       " \t[.obscene]:[torch.cuda.LongTensor of size 64 (GPU 0)]\n",
       " \t[.threat]:[torch.cuda.LongTensor of size 64 (GPU 0)]\n",
       " \t[.insult]:[torch.cuda.LongTensor of size 64 (GPU 0)]\n",
       " \t[.identity_hate]:[torch.cuda.LongTensor of size 64 (GPU 0)])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 16443, 113053,      2],\n",
       "        [ 13732,  37329,      2],\n",
       "        [    77, 321641,      2],\n",
       "        [   648, 278134,      2],\n",
       "        [  8581, 140914,      2],\n",
       "        [ 61261,  44571,      2],\n",
       "        [    57,  66469,      2],\n",
       "        [161173,  27287,      2],\n",
       "        [ 11240, 406048,      2],\n",
       "        [  5149,  14142,      2],\n",
       "        [   457,  46067,      2],\n",
       "        [304063,  57161,      2],\n",
       "        [  2305, 359064,      2],\n",
       "        [  5928,  57161,      2],\n",
       "        [ 76051,    407,      2],\n",
       "        [     9, 456340,      2],\n",
       "        [ 47658,  40468,      2],\n",
       "        [    69, 320830,      2],\n",
       "        [   345, 271389,      2],\n",
       "        [  2344,  73992,      2],\n",
       "        [  4998,  57113,      2],\n",
       "        [  7962, 112180,      2],\n",
       "        [  4716, 309280,      2],\n",
       "        [289276,  10401,      2],\n",
       "        [  1971, 278381,      2],\n",
       "        [  1123,   2304,      2],\n",
       "        [  3899, 221009,      2],\n",
       "        [  1101, 264264,      2],\n",
       "        [104247,  32200,      2],\n",
       "        [   648, 431696,      2],\n",
       "        [  2688, 362321,      2],\n",
       "        [  2316, 113771,      2],\n",
       "        [   293, 422316,      2],\n",
       "        [  3221, 414883,      2],\n",
       "        [   779, 283421,      2],\n",
       "        [  1101, 427349,      2],\n",
       "        [   407, 219600,      2],\n",
       "        [137220,   1012,      2],\n",
       "        [226606, 461505,      2],\n",
       "        [ 66966, 208737,      2],\n",
       "        [319894, 218525,      2],\n",
       "        [430050,   2162,      2],\n",
       "        [  7207,  57170,      2],\n",
       "        [  4042,   5950,      2],\n",
       "        [  1123,    798,      2],\n",
       "        [  2989,   1609,      2],\n",
       "        [ 57216,  73654,      2],\n",
       "        [319783,      2,      1],\n",
       "        [ 46461,      2,      1],\n",
       "        [445350,      2,      1],\n",
       "        [ 81922,      2,      1],\n",
       "        [163123,      2,      1],\n",
       "        [454503,      2,      1],\n",
       "        [465098,      2,      1],\n",
       "        [133888,      2,      1],\n",
       "        [426535,      2,      1],\n",
       "        [465151,      2,      1],\n",
       "        [133901,      2,      1],\n",
       "        [317888,      2,      1],\n",
       "        [123043,      2,      1],\n",
       "        [220723,      2,      1],\n",
       "        [445430,      2,      1],\n",
       "        [112142,      2,      1],\n",
       "        [202122,      2,      1]], device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observe how all the sentences are of similar length\n",
    "sample_batch[1].comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toxic field\n",
    "sample_batch[1].toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 16443, 113053,      2],\n",
       "        [ 13732,  37329,      2],\n",
       "        [    77, 321641,      2],\n",
       "        [   648, 278134,      2],\n",
       "        [  8581, 140914,      2],\n",
       "        [ 61261,  44571,      2],\n",
       "        [    57,  66469,      2],\n",
       "        [161173,  27287,      2],\n",
       "        [ 11240, 406048,      2],\n",
       "        [  5149,  14142,      2],\n",
       "        [   457,  46067,      2],\n",
       "        [304063,  57161,      2],\n",
       "        [  2305, 359064,      2],\n",
       "        [  5928,  57161,      2],\n",
       "        [ 76051,    407,      2],\n",
       "        [     9, 456340,      2],\n",
       "        [ 47658,  40468,      2],\n",
       "        [    69, 320830,      2],\n",
       "        [   345, 271389,      2],\n",
       "        [  2344,  73992,      2],\n",
       "        [  4998,  57113,      2],\n",
       "        [  7962, 112180,      2],\n",
       "        [  4716, 309280,      2],\n",
       "        [289276,  10401,      2],\n",
       "        [  1971, 278381,      2],\n",
       "        [  1123,   2304,      2],\n",
       "        [  3899, 221009,      2],\n",
       "        [  1101, 264264,      2],\n",
       "        [104247,  32200,      2],\n",
       "        [   648, 431696,      2],\n",
       "        [  2688, 362321,      2],\n",
       "        [  2316, 113771,      2],\n",
       "        [   293, 422316,      2],\n",
       "        [  3221, 414883,      2],\n",
       "        [   779, 283421,      2],\n",
       "        [  1101, 427349,      2],\n",
       "        [   407, 219600,      2],\n",
       "        [137220,   1012,      2],\n",
       "        [226606, 461505,      2],\n",
       "        [ 66966, 208737,      2],\n",
       "        [319894, 218525,      2],\n",
       "        [430050,   2162,      2],\n",
       "        [  7207,  57170,      2],\n",
       "        [  4042,   5950,      2],\n",
       "        [  1123,    798,      2],\n",
       "        [  2989,   1609,      2],\n",
       "        [ 57216,  73654,      2],\n",
       "        [319783,      2,      1],\n",
       "        [ 46461,      2,      1],\n",
       "        [445350,      2,      1],\n",
       "        [ 81922,      2,      1],\n",
       "        [163123,      2,      1],\n",
       "        [454503,      2,      1],\n",
       "        [465098,      2,      1],\n",
       "        [133888,      2,      1],\n",
       "        [426535,      2,      1],\n",
       "        [465151,      2,      1],\n",
       "        [133901,      2,      1],\n",
       "        [317888,      2,      1],\n",
       "        [123043,      2,      1],\n",
       "        [220723,      2,      1],\n",
       "        [445430,      2,      1],\n",
       "        [112142,      2,      1],\n",
       "        [202122,      2,      1]], device='cuda:0')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another way to access the variables\n",
    "getattr(sample_batch[1], 'comment_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
